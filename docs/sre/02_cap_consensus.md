# 02. CAP-теорема и распределённый консенсус

> **Сложность:** ⭐⭐ Средний уровень
> **Вопросы из списка:** 3, 4

---

## Вопрос 3: CAP-теорема и PACELC

### Что такое распределённая система?

Прежде чем говорить о CAP, поймём контекст.

**Распределённая система** — это несколько компьютеров (узлов), которые:
- Работают вместе как единое целое
- Общаются по сети
- Могут отказывать независимо друг от друга

```
┌─────────┐     ┌─────────┐     ┌─────────┐
│  Node 1 │────│  Node 2 │────│  Node 3 │
│ (Master)│     │(Replica)│     │(Replica)│
└─────────┘     └─────────┘     └─────────┘
     │               │               │
     └───────────────┴───────────────┘
              Сеть (может упасть!)
```

### CAP-теорема

**CAP** — это теорема, доказанная в 2002 году. Она говорит:

> В распределённой системе при сетевом разделении (network partition) 
> можно выбрать только ДВА из ТРЁХ свойств.

#### Три свойства CAP

| Буква | Свойство | Что значит |
|-------|----------|------------|
| **C** | Consistency (Согласованность) | Все узлы видят одинаковые данные в один момент времени |
| **A** | Availability (Доступность) | Каждый запрос получает ответ (не обязательно актуальный) |
| **P** | Partition Tolerance (Устойчивость к разделению) | Система работает, даже если сеть между узлами разорвана |

#### Визуализация

```
                    CAP
                     │
         ┌───────────┼───────────┐
         ▼           ▼           ▼
    Consistency  Availability  Partition
                               Tolerance
         │           │           │
         └─────┬─────┘           │
               │                 │
            Выбери 2!            │
               │                 │
         ┌─────┴─────┐           │
         ▼           ▼           │
        CP          AP           │
    (жертвуем A) (жертвуем C)    │
                                 │
         P — обязателен в реальности!
```

### Почему P обязателен?

В реальном мире **сеть ВСЕГДА может разорваться**:
- Кабель перерезали
- Роутер завис
- Датацентр потерял связь

Поэтому на практике выбор только между:
- **CP** — Consistency + Partition Tolerance (жертвуем доступностью)
- **AP** — Availability + Partition Tolerance (жертвуем согласованностью)

### CP системы

**Выбор:** Лучше не отвечать, чем отвечать неправильно.

```
Сценарий: Сеть между узлами разорвалась

┌─────────┐          ┌─────────┐
│  Node 1 │    ✗     │  Node 2 │
│  data=5 │──────────│  data=? │
└─────────┘          └─────────┘
     │                    │
  Клиент              Клиент
  пишет 5             читает
     │                    │
     ▼                    ▼
   OK ✓               ОШИБКА! ✗
                    (недоступен)
```

**Примеры CP систем:**
- **ZooKeeper** — координация
- **etcd** — конфигурация
- **HBase** — база данных
- Банковские системы (лучше отказать, чем списать дважды)

### AP системы

**Выбор:** Лучше ответить устаревшими данными, чем не ответить.

```
Сценарий: Сеть между узлами разорвалась

┌─────────┐          ┌─────────┐
│  Node 1 │    ✗     │  Node 2 │
│  data=5 │──────────│  data=3 │ (старое значение)
└─────────┘          └─────────┘
     │                    │
  Клиент              Клиент
  пишет 5             читает
     │                    │
     ▼                    ▼
   OK ✓                 3 ✓
                    (устаревшее, но ответил!)
```

**Примеры AP систем:**
- **Cassandra** — база данных
- **DynamoDB** — база данных
- **DNS** — система доменных имён
- Счётчик лайков (не страшно показать чуть меньше)

### PACELC — расширение CAP

CAP говорит только о ситуации **при сетевом разделении (P)**. 
А что происходит в **нормальном режиме**?

**PACELC** добавляет вторую часть:

```
IF Partition (P):
    Choose Availability (A) OR Consistency (C)
ELSE (E) — в нормальном режиме:
    Choose Latency (L) OR Consistency (C)
```

#### Полная формула

| Система | При разделении (PAC) | В норме (ELC) |
|---------|---------------------|---------------|
| **PA/EL** | Availability | Latency |
| **PA/EC** | Availability | Consistency |
| **PC/EL** | Consistency | Latency |
| **PC/EC** | Consistency | Consistency |

#### Примеры

| Система | PACELC | Объяснение |
|---------|--------|------------|
| Cassandra | PA/EL | Всегда отвечает, всегда быстро |
| MongoDB | PA/EC | Отвечает при разделении, но в норме консистентна |
| HBase | PC/EC | Всегда консистентна, может быть медленной |

### Практический выбор

```
┌─────────────────────────────────────────────────────────┐
│                   КАК ВЫБРАТЬ?                          │
├─────────────────────────────────────────────────────────┤
│                                                         │
│  Что важнее?                                            │
│                                                         │
│  💰 Деньги, транзакции    →  CP (консистентность)       │
│     "Нельзя списать дважды"                             │
│                                                         │
│  👁️ Просмотры, лайки      →  AP (доступность)           │
│     "Лучше показать что-то"                             │
│                                                         │
│  📦 Заказы, инвентарь     →  Зависит от бизнеса         │
│     Oversell страшнее, чем "товар закончился"?          │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

---

## Вопрос 4: Проблема распределённого консенсуса

### Что такое консенсус?

**Консенсус** — это когда несколько узлов **договариваются** о чём-то:
- Какое значение записать?
- Кто сейчас лидер?
- Какой порядок транзакций?

### Почему это сложно?

В распределённой системе:
1. **Узлы могут падать** — и мы не знаем, упал он или просто медленный
2. **Сеть ненадёжна** — сообщения теряются, дублируются, задерживаются
3. **Нет единого времени** — часы на разных серверах расходятся

### Проблема двух генералов

Классическая иллюстрация проблемы:

```
        ┌─────────────────────────────────────┐
        │           ВРАГ (долина)             │
        └─────────────────────────────────────┘
                         │
    ┌────────────┐       │       ┌────────────┐
    │ Генерал A  │       │       │ Генерал B  │
    │  (армия)   │◄──────┼──────►│  (армия)   │
    └────────────┘   гонцы       └────────────┘
                  (могут быть
                   убиты!)

    Задача: Атаковать одновременно
    Проблема: Как убедиться, что оба готовы?
```

**Проблема:**
- A отправляет: "Атакуем в 6 утра"
- B получил? Неизвестно (гонец мог погибнуть)
- B отправляет: "Подтверждаю"
- A получил подтверждение? Неизвестно
- И так до бесконечности...

**Вывод:** В ненадёжной сети **невозможно** достичь 100% гарантии консенсуса.

### Проблема византийских генералов

Ещё сложнее: а что если **некоторые узлы врут**?

```
    ┌────────────┐     ┌────────────┐     ┌────────────┐
    │ Генерал A  │     │ Генерал B  │     │ Генерал C  │
    │ "Атакуем!" │     │  ПРЕДАТЕЛЬ │     │ "Атакуем!" │
    └────────────┘     └────────────┘     └────────────┘
          │                  │                  │
          │    "Отступаем!"  │    "Атакуем!"    │
          │◄─────────────────┼─────────────────►│
          │                  │                  │
        A думает:          B врёт:           C думает:
        "Все атакуют"    разное всем       "Все атакуют"
```

**Byzantine Fault Tolerance (BFT)** — алгоритмы, устойчивые к "предателям".
Используются в блокчейне.

### Решения: Алгоритмы консенсуса

#### 1. Paxos (1989)

Первый алгоритм консенсуса. Очень сложный для понимания.

```
Роли:
- Proposer — предлагает значение
- Acceptor — голосует
- Learner — узнаёт результат

Фазы:
1. Prepare: Proposer просит разрешения
2. Promise: Acceptors обещают
3. Accept: Proposer предлагает значение
4. Accepted: Acceptors принимают
```

**Проблема:** Сложно реализовать правильно.

#### 2. Raft (2014)

Создан как "понятный Paxos". Используется в etcd, Consul.

```
Роли:
- Leader — один главный, принимает все записи
- Follower — реплики, следуют за лидером
- Candidate — кандидат в лидеры при выборах

┌─────────────────────────────────────────────────────────┐
│                    RAFT: НОРМАЛЬНАЯ РАБОТА              │
├─────────────────────────────────────────────────────────┤
│                                                         │
│   Клиент ──► Leader ──► Followers                       │
│              │          │                               │
│              │  1. Записать в лог                       │
│              │  2. Реплицировать                        │
│              │  3. Дождаться большинства                │
│              │  4. Закоммитить                          │
│              │  5. Ответить клиенту                     │
│              ▼                                          │
│            OK ✓                                         │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

**Выборы лидера в Raft:**

```
┌─────────────────────────────────────────────────────────┐
│                    RAFT: ВЫБОРЫ ЛИДЕРА                  │
├─────────────────────────────────────────────────────────┤
│                                                         │
│  1. Follower не получает heartbeat от Leader            │
│  2. Становится Candidate                                │
│  3. Увеличивает term (эпоху)                            │
│  4. Голосует за себя                                    │
│  5. Просит голоса у других                              │
│  6. Если большинство — становится Leader                │
│                                                         │
│  Timeout: 150-300ms (рандомный, чтобы избежать split)   │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

#### 3. ZAB (Zookeeper Atomic Broadcast)

Используется в ZooKeeper. Похож на Raft.

### Кворум (Quorum)

**Кворум** — минимальное количество узлов для принятия решения.

```
Формула: Quorum = (N / 2) + 1

Примеры:
- 3 узла → кворум = 2 (можем потерять 1)
- 5 узлов → кворум = 3 (можем потерять 2)
- 7 узлов → кворум = 4 (можем потерять 3)
```

**Почему это работает:**

```
Кластер из 5 узлов:

Запись: нужно 3 подтверждения
Чтение: нужно 3 ответа

┌───┐ ┌───┐ ┌───┐ ┌───┐ ┌───┐
│ 1 │ │ 2 │ │ 3 │ │ 4 │ │ 5 │
└───┘ └───┘ └───┘ └───┘ └───┘
  ✓     ✓     ✓     ✗     ✗
        │
        └── Запись успешна (3 из 5)

Любое чтение 3 узлов пересечётся
с записью минимум на 1 узле!
```

### Split Brain

**Split Brain** — когда сеть разделилась и каждая часть думает, что она главная.

```
┌─────────────────┐         ┌─────────────────┐
│   Partition 1   │    ✗    │   Partition 2   │
│  ┌───┐ ┌───┐    │─────────│    ┌───┐ ┌───┐  │
│  │ 1 │ │ 2 │    │  сеть   │    │ 3 │ │ 4 │  │
│  └───┘ └───┘    │ разрыв  │    └───┘ └───┘  │
│  "Мы главные!"  │         │  "Мы главные!"  │
└─────────────────┘         └─────────────────┘

Проблема: Оба раздела принимают записи
Результат: Конфликтующие данные!
```

**Решение:** Кворум! Только раздел с большинством может работать.

```
5 узлов, разделение 2-3:

Partition 1: [1, 2]     → 2 < 3 (кворум) → НЕ РАБОТАЕТ
Partition 2: [3, 4, 5]  → 3 ≥ 3 (кворум) → РАБОТАЕТ
```

### Сравнение алгоритмов

| Алгоритм | Сложность | Где используется |
|----------|-----------|------------------|
| Paxos | Очень сложный | Google Chubby |
| Raft | Понятный | etcd, Consul, CockroachDB |
| ZAB | Средний | ZooKeeper |
| PBFT | Сложный (BFT) | Hyperledger, блокчейны |

### Практические примеры выбора CP vs AP

```
┌─────────────────────────────────────────────────────────┐
│              ПРАКТИЧЕСКИЕ ПРИМЕРЫ                       │
├─────────────────────────────────────────────────────────┤
│                                                         │
│  🏦 БАНКОВСКИЙ ПЕРЕВОД → CP                             │
│  ─────────────────────────                              │
│  Требование: Нельзя списать деньги дважды               │
│  Решение: При сетевом разделении — отказать в операции  │
│  Системы: PostgreSQL, MySQL, традиционные СУБД          │
│                                                         │
│  📱 ЛЕНТА СОЦСЕТИ → AP                                  │
│  ────────────────────                                   │
│  Требование: Всегда показывать что-то пользователю      │
│  Решение: Показать устаревшие посты лучше, чем ничего   │
│  Системы: Cassandra, DynamoDB                           │
│                                                         │
│  🛒 КОРЗИНА ПОКУПОК → AP с merge                        │
│  ────────────────────────────                           │
│  Требование: Не терять товары в корзине                 │
│  Решение: При конфликте — объединить корзины            │
│  Системы: Amazon DynamoDB (shopping cart paper)         │
│                                                         │
│  📊 СЧЁТЧИК ПРОСМОТРОВ → AP (eventual)                  │
│  ────────────────────────────────────                   │
│  Требование: Примерное число, не точное                 │
│  Решение: Показать приблизительное значение             │
│  Системы: Redis, Cassandra counters                     │
│                                                         │
│  🔐 СИСТЕМА АВТОРИЗАЦИИ → CP                            │
│  ──────────────────────────                             │
│  Требование: Нельзя дать доступ неавторизованному       │
│  Решение: При сомнениях — отказать в доступе            │
│  Системы: etcd, ZooKeeper, Consul                       │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

### Linearizability vs Sequential Consistency

```
┌─────────────────────────────────────────────────────────┐
│           УРОВНИ КОНСИСТЕНТНОСТИ                        │
├─────────────────────────────────────────────────────────┤
│                                                         │
│  LINEARIZABILITY (линеаризуемость) — самая строгая      │
│  ─────────────────────────────────────────────────      │
│  • Операции выглядят мгновенными                        │
│  • Как будто есть одна копия данных                     │
│  • После записи — все видят новое значение              │
│                                                         │
│  Клиент 1: write(x=1) ─────────────────────────►        │
│  Клиент 2:              read(x) → 1 (гарантировано)     │
│                                                         │
│  SEQUENTIAL CONSISTENCY — слабее                        │
│  ────────────────────────────────                       │
│  • Операции каждого клиента в порядке                   │
│  • Но глобальный порядок может отличаться               │
│                                                         │
│  EVENTUAL CONSISTENCY — самая слабая                    │
│  ────────────────────────────────────                   │
│  • Когда-нибудь все увидят одинаковое                   │
│  • Нет гарантий когда                                   │
│                                                         │
│  Сильнее ◄─────────────────────────────────► Слабее     │
│  Linearizable → Sequential → Causal → Eventual          │
│  (медленнее)                              (быстрее)     │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

### Фундаментальные ограничения

```
┌─────────────────────────────────────────────────────────┐
│             ФУНДАМЕНТАЛЬНЫЕ ОГРАНИЧЕНИЯ                 │
├─────────────────────────────────────────────────────────┤
│                                                         │
│  1. FLP IMPOSSIBILITY (1985)                            │
│     ────────────────────────                            │
│     В асинхронной системе с хотя бы одним               │
│     сбойным узлом НЕВОЗМОЖНО гарантировать              │
│     консенсус за конечное время.                        │
│                                                         │
│     Решение: Используем таймауты (делаем систему        │
│     частично синхронной)                                │
│                                                         │
│  2. СКОРОСТЬ СВЕТА                                      │
│     ────────────────                                    │
│     Москва ↔ Нью-Йорк: ~80ms RTT минимум                │
│     Синхронная репликация = +80ms к каждой записи       │
│                                                         │
│  3. КОМПРОМИССЫ НЕИЗБЕЖНЫ                               │
│     ─────────────────────                               │
│     Нельзя одновременно:                                │
│     • Быстро                                            │
│     • Консистентно                                      │
│     • Доступно                                          │
│     Выбирай 2 из 3!                                     │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

---

## Ключевые термины

| Термин | Определение |
|--------|-------------|
| **CAP** | Теорема: Consistency + Availability + Partition Tolerance — выбери 2 |
| **PACELC** | Расширение CAP: что выбрать в нормальном режиме |
| **Консенсус** | Процесс достижения согласия между узлами |
| **Paxos** | Первый алгоритм консенсуса (сложный) |
| **Raft** | Понятный алгоритм консенсуса (Leader-based) |
| **Кворум** | Минимальное число узлов для решения (N/2 + 1) |
| **Split Brain** | Разделение кластера на несколько "главных" частей |
| **Byzantine Fault** | Ситуация, когда узел может врать/вести себя произвольно |

---

## Что запомнить

1. **CAP:** При сетевом разделении выбирай CP или AP
2. **P обязателен** — сеть всегда может разорваться
3. **Консенсус сложен** — используй готовые решения (etcd, ZooKeeper)
4. **Кворум = N/2 + 1** — защита от split brain
5. **Raft понятнее Paxos** — если нужно разобраться, начни с Raft

---

*Следующий файл: [03. Базы данных — основы](03_databases_basics.md)*

