
# ADR: Архитектура сервиса аренды пауэрбанков (команда 8)

**Дата:** 20.11.2025

**Состав команды:** Салахов Данияр, Фролов Александр, Юлдашев Сарвар, Майорова Марина

**Команда:** 8

**Group:** architecture / integration / data / billing

**Статус:** proposed (на рассмотрении преподавателя)  

---

## Issue / Контекст и постановка задачи

Нужно превратить учебную заготовку (скрипт с in-memory словарями и заглушками) в полноценную систему:

- с **микросервисной архитектурой**;
- с отдельной **БД**;
- с учётом NFR по **Maintainability, Reliability, Scalability**;
- с выполнением функциональных требований варианта команды 8.

### Functional Requirements (FR)

1. **Три основных handler’а:**
   - `POST /rentals/quote` — посчитать оффер (цену, депозит, TTL оффера).
   - `POST /rentals/start` — начать аренду по ранее полученному офферу.
   - `POST /rentals/{order_id}/stop` — остановить аренду, вернуть итоговую сумму.
   - Вспомогательная ручка: `GET /rentals/{order_id}/status` — статус аренды и накопленная стоимость.

2. **Источники данных (через HTTP во внешний `external-stubs`):**
   - `stations` — данные по станции.
   - `tariffs` — тарифная зона.
   - `users` — профиль пользователя (подписка/trusted).
   - `configs` — конфигурация и feature-флаги.
   - `payments` — удержание и списание денег.

3. **Логика работы офферов:**
   - Контроль **свежести оффера** (TTL).
   - **Текущая накопленная стоимость** аренды.
   - **Регулярные списания** в течение аренды.
   - При невозможности списания — **навешивать долг**.
   - **Периодические попытки списания долга** с бэкоффом.
   - При достижении `R_BUYOUT` (платежи + долг) — **автовыкуп**, статус `BUYOUT`.

### Non-Functional Requirements (NFR)

**Maintainability**

- Возможность добавлять новые источники данных и менять бизнес-логику без переписывания всего сервиса.
- Чёткое разделение:
  - бизнес-логики,
  - работы с внешними сервисами,
  - хранения данных,
  - фоновых процессов (биллинг).

**Reliability**

- Источники разделены на:
  - **Критичный**:
    - `stations` — без станции аренду начать нельзя.
  - **Некритичные** (должна быть деградация/фоллбэк):
    - `configs` — при старте обязательна успешная загрузка; затем можно работать по старому конфигу.
    - `tariffs` — LRU-кэш + TTL (старые данные > N минут не использовать).
    - `users` — при недоступности — фоллбэк к «жадному» профилю (нет подписки, не trusted).
    - `payments` — при недоступности аренда запускается, долг растёт.

- Идемпотентность:
  - повторный `/start` с тем же `Idempotency-Key` не создаёт дубликата аренды;
  - повторный `/stop` не ломает финальный статус.

**Scalability**

Для нашей команды (номер 8) заданы параметры:

- **X = 10** — внешняя нагрузка на создание аренды (`/rentals/start`) в RPS.
- **Y = 10** — количество пользователей/исполнителей:
  - каждый раз в минуту запрашивает статус => `Y/60` RPS на `/status`.
- **Z = 1 kB** — размер хранения одного заказа (минимальный набор данных).

Требование: система **линейно масштабируется** по X и Y, поддерживает горизонтальное масштабирование:

- `rental-core` — через горизонтальный скейлинг,
- `billing-worker` — через шардирование / несколько воркеров.

---

## Assumptions and Constraints

**Предположения:**

- Единственная основная БД — PostgreSQL.
- Код пишется на Python, веб-фреймворк — FastAPI.
- Внешние системы моделируются сервисом `external-stubs`.

**Ограничения:**

- Учебный проект — не вводим тяжёлые инфраструктурные компоненты (Kafka и т.п.), только то, что можно поднять `docker-compose`.
- Все внешние интеграции — синхронные HTTP вызовы.
- Храним только минимально необходимый набор данных, эквивалентный Z = 1 kB на заказ.




## Positions / Рассматриваемые варианты архитектуры

В процессе проектирования мы явно зафиксировали несколько архитектурных позиций (вариантов), которые могли бы удовлетворить функциональные и нефункциональные требования (FR, NFR). Даже те варианты, которые формально выходят за рамки учебного задания, рассматривались, чтобы наполнить этот пункт ADR, требуемый по заданию. 

### Position A — Монолитный сервис `rental-service` с фоновыми задачами внутри

**Идея.**  
Один сервис `rental-service`, написанный на FastAPI, который одновременно:

- обрабатывает все HTTP-запросы (`/rentals/quote`, `/start`, `/stop`, `/status`);
- по внутреннему планировщику (cron/apscheduler/background tasks) выполняет периодический биллинг:
  - пересчёт накопленной стоимости;
  - попытки списания;
  - обработку долгов и `R_BUYOUT`.

Хранение данных — единая БД PostgreSQL с теми же сущностями (`rentals`, `quotes`, `payment_attempts`, `debts`, `idempotency_keys`).

**Плюсы (почему вариант вообще рассматривался).**

- Максимально простая инфраструктура:
  - один кодовый репозиторий, один контейнер, один деплой;
  - проще локальная разработка и отладка.
- Все операции над арендами и биллингом происходят внутри одного процесса:
  - нет сетевого взаимодействия между сервисами;
  - нет распределённых транзакций, всё в рамках одной БД.

**Минусы и ограничения.**

- Фактически это монолит, что противоречит цели задания «построить микросервисную архитектуру».
- Масштабирование по X и Y (нагрузка на `/start` и `/status`) ограничено:
  - API-запросы и фоновые биллинговые задачи конкурируют за одни и те же ресурсы процесса;
  - при росте нагрузки биллинг может «подъедать» CPU и память, увеличивая задержки HTTP-ответов.
- Падает maintainability:
  - в одном кодовом базисе смешиваются HTTP-слой, бизнес-логика аренды и периодическая денежная логика;
  - сложнее выделять ответственность и тестировать компоненты по отдельности.

**Вывод.**  
Вариант A удобен как верхняя граница самого простого решения, но плохо соответствует требованиям к микросервисной архитектуре, масштабируемости и поддерживаемости, поэтому использовался только как отправная точка для сравнения.

---

### Position B — Два сервиса: `rental-core` + `billing-worker` с общей БД (текущее решение)

**Идея.**  
Разделить систему на два микросервиса:

- `rental-core` — HTTP-API и состояние аренды:
  - обрабатывает `/rentals/quote`, `/start`, `/stop`, `/status`, `/health`;
  - обращается к внешним системам через слой клиентов;
  - читает и пишет данные аренды в БД.
- `billing-worker` — фоновый воркер:
  - по таймеру обходит активные аренды;
  - пересчитывает начисления;
  - создаёт записи о попытках списания;
  - ведёт долги и меняет статус аренды на `BUYOUT` при достижении `R_BUYOUT`.

Оба сервиса используют **общую БД PostgreSQL** с единым набором таблиц.

**Плюсы.**

- Чёткое разделение ответственности:
  - `rental-core` — синхронное пользовательское API;
  - `billing-worker` — асинхронная денежная логика.
- Простое горизонтальное масштабирование:
  - `rental-core` stateless, можно поднимать несколько экземпляров за балансировщиком;
  - количество экземпляров `billing-worker` можно увеличивать отдельно (шардирование по арендам или по времени).
- Инфраструктура остаётся простой для учебного проекта:
  - не нужны дополнительные брокеры сообщений или сложные компоненты;
  - достаточно `docker-compose` с двумя сервисами и одной БД.
- Хороший баланс между соответствием NFR (maintainability, reliability, scalability) и сложностью реализации.

**Минусы и ограничения.**

- Всё ещё единая БД — отсутствие изоляции данных между онлайн-операциями и биллингом:
  - возможны конкурирующие блокировки (конкурентные апдейты по одной аренде);
  - требуется аккуратно проектировать транзакции и уровни изоляции.

---

### Position C — `rental-core` + `billing-worker` + очередь сообщений (RabbitMQ / Redis Streams)

**Идея.**  
Сохранить разделение на `rental-core` и `billing-worker`, но добавить **явный асинхронный канал** взаимодействия:

- `rental-core`:
  - по событиям (создание аренды, изменение статуса, проблемы с оплатой) публикует сообщения в очередь или топик (например, RabbitMQ, Redis Streams);
  - отвечает пользователю сразу после записи в БД и публикации события.
- `billing-worker`:
  - подписывается на события из очереди;
  - на их основе обновляет `payment_attempts`, `debts`, статусы аренд;
  - может хранить часть своего состояния отдельно (кэш долгов, счётчики ретраев).

БД остаётся общей или частично общей; ключевое отличие — появление брокера сообщений.

**Плюсы.**

- Более слабое зацепление между сервисами:
  - `billing-worker` реагирует на бизнес-события, а не читает БД «в лоб» по таймеру;
  - легче добавлять новые потребители событий (например, сервис уведомлений).
- Лучшая устойчивость к пикам нагрузки:
  - очередь буферизует всплески (при росте X/Y растёт длина очереди, но не ломается API);
  - `billing-worker` можно масштабировать, читая очередь параллельно.

**Минусы и ограничения.**

- Существенно более сложная инфраструктура:
  - появляется брокер сообщений, который нужно инсталлировать, конфигурировать и мониторить;
  - сложнее локальная разработка и деплой (ещё один сервис в `docker-compose`).
- Для учебного задания есть явное ограничение «не вводить тяжёлые инфраструктурные компоненты (Kafka и т.п.)»:
  - формально RabbitMQ/Redis Streams можно поднять, но это усложняет стенд и отвлекает от основной цели.
- Увеличивается когнитивная сложность:
  - появляется асинхронная обработка, ретраи на уровне очереди, dead-letter механизмы и т.д.

**Вывод.**  
Вариант C даёт более «производственную» архитектуру с явной событийной шиной, но инфраструктурно тяжелее и избыточен для заданной учебной нагрузки X=10, Y=10, Z=1 kB.

---


## Argument / Обоснование выбора

При выборе архитектуры мы сравнивали варианты A, B и C по нескольким критериям:

- соответствие учебному заданию (микросервисная архитектура, ограниченная инфраструктура);
- поддерживаемость (maintainability);
- надёжность (reliability);
- масштабируемость (scalability) по X и Y;
- сложность реализации и сопровождения.

### Сравнение Position A vs Position B

- **Микросервисность.**
  - A: фактически монолит с фоновыми задачами → не отражает идеи микросервисной архитектуры.
  - B: даёт два независимых сервиса с разделением ответственности (API и биллинг).

    **Чем независимые сервисы лучше, и что действительно важно:**
      - У каждого сервиса своя зона ответственности
      - Можно независимо обновлять нужные сервисы
      - Распределение нагрузок можно производить более контролируемо

- **Масштабируемость.**
  - A: API-запросы и биллинг конкурируют за один процесс/пул потоков; рост X/Y ухудшает латентность для всех.
  - B: `rental-core` и `billing-worker` масштабируются независимо; можно поднимать больше реплик только там, где растёт нагрузка.

- **Поддерживаемость.**
  - A: в одном кодовом дереве смешаны HTTP-слой, бизнес-логика и периодические задачи.
  - B: денежная логика вынесена в отдельный воркер; проще менять биллинг, не трогая API, и наоборот.

- **Сложность.**
  - A: инфраструктурно проще, но сложнее логически (много ролей у одного сервиса).
  - B: появляется второй сервис и деплой, но общий уровень сложности для команды остаётся приемлемым.

**Вывод:** Position B даёт значимый выигрыш в масштабируемости и поддерживаемости по сравнению с Position A, при умеренном увеличении инфраструктурной сложности.

### Сравнение Position B vs Position C

- **Инфраструктура.**
  - B: требуется только две службы и одна БД → укладывается в ограничение «поднять через docker-compose».
  - C: добавляется брокер сообщений (RabbitMQ/Redis Streams и т.п.), который нужно устанавливать, настраивать и мониторить.

- **Масштабируемость и надёжность.**
  - B: биллинг работает по таймеру, что достаточно для заданной нагрузки (X=10, Y=10); пики нагрузок обрабатываются за счёт масштабирования воркера и БД.
  - C: даёт более гибкую обработку пиков и явную событийную модель, но это преимущество не критично при текущих требованиях.

- **Сложность разработки.**
  - B: взаимодействие через общую БД, меньше концепций для команды.
  - C: нужно проектировать формат сообщений, обработку ретраев, ошибочные сообщения (DLQ) и т.п.

**Вывод:** Position C архитектурно «красивее» и ближе к промышленным системам, но существенно усложняет инфраструктуру и выходит за рамки учебных ограничений. Для заданной нагрузки преимущества не окупают усложнение.

### Итоговое решение

Учитывая:

- требование продемонстрировать микросервисную архитектуру;
- ограничение по инфраструктуре (только то, что можно поднять через `docker-compose`);
- учебную нагрузку X=10 RPS, Y=10 пользователей и малый объём данных Z=1 kB на заказ;

мы выбрали **Position B** (два сервиса `rental-core` и `billing-worker` с общей БД PostgreSQL) как оптимальный баланс между соответствием требованиям и сложностью реализации.




## Related requirements / Связанные требования

### Функциональные требования (FR)

- **FR-1: Handlers `/rentals/quote`, `/start`, `/stop`, `/status`.**  
  Реализуются в сервисе `rental-core` как HTTP-эндпоинты. Сервис обращается к БД и внешним источникам через слой клиентов.

- **FR-2: Интеграция с внешними системами (`stations`, `tariffs`, `users`, `configs`, `payments`).**  
  Инкапсулирована в модуле клиентов (`clients.py`) в `rental-core` и, при необходимости, в `billing-worker`. Там же реализуются кэши и стратегии деградации.

- **FR-3: Логика офферов и биллинга (TTL оффера, накопленная стоимость, регулярные списания, долги, `R_BUYOUT`).**  
  - Офферы (`quotes`) создаются и валидируются в `rental-core`.  
  - Регулярные списания, управление долгами и смена статуса на `BUYOUT` выполняются в `billing-worker` на основе таблиц `rentals`, `payment_attempts`, `debts`.

### Нефункциональные требования (NFR)

- **NFR-Maintainability (поддерживаемость).**  
  - Разделение на `rental-core` и `billing-worker` уменьшает связность и упрощает изменение биллинга без изменений API.  
  - Слой клиентов отделяет бизнес-логику от интеграций.

- **NFR-Reliability (надёжность).**  
  - Чётко определены критичный (`stations`) и некритичные источники с фоллбэками (`configs`, `tariffs`, `users`, `payments`).  
  - Идемпотентность `/start` и корректная обработка повторных `/stop` защищают от дублей и рассинхронизации.

- **NFR-Scalability (масштабируемость).**  
  - `rental-core` stateless и может масштабироваться горизонтально под рост X и Y.  
  - `billing-worker` можно масштабировать независимо (несколько воркеров, шардирование по арендам).  
  - Нагрузка на БД оценена и остаётся в пределах комфортных значений для одной PostgreSQL.


## Related principles / Связанные принципы

При принятии решения использовались следующие явные/неявные архитектурные принципы:

- **P1: "Простота инфраструктуры".**  
  Используем только те компоненты, которые можно поднять через `docker-compose` в учебной среде (без Kafka и тяжёлых брокеров).

- **P2: "Чёткие границы ответственности".**  
  HTTP-API (`rental-core`) не содержит периодической биллинговой логики; фоновая обработка вынесена в `billing-worker`.

- **P3: "Деградация лучше полного отказа".**  
  Некритичные внешние источники (`tariffs`, `users`, `configs`, `payments`) имеют кэш или фоллбэки; при их недоступности система работает в деградированном режиме.

- **P4: "Линейная масштабируемость по X и Y".**  
  Архитектура должна позволять увеличивать количество инстансов `rental-core` и `billing-worker` без серьёзных переделок.




## Decision / Архитектурное решение

### Микросервисное разбиение

**Решение:** система разделена на три основных компонента.

1. **`rental-core`**
   - FastAPI-сервис (`services/rental-core/app/main.py`).
   - Отвечает за:
     - `POST /rentals/quote`
     - `POST /rentals/start`
     - `POST /rentals/{order_id}/stop`
     - `GET /rentals/{order_id}/status`
     - `GET /health`
   - Хранит и читает состояние аренды в БД.
   - Не ходит во внешние сервисы напрямую — использует слой клиентов (`clients.py`), где инкапсулированы HTTP-вызовы, кэши и фоллбэки.

2. **`billing-worker`**
   - Отдельный сервис (`services/billing-worker/main.py`), работающий как фоновый воркер.
   - Периодически (каждые `BILLING_TICK_SEC` секунд):
     - находит активные аренды (`status='ACTIVE'`);
     - пересчитывает начисленную сумму;
     - пытается списать деньги;
     - вешает долг при неуспехе;
     - ретраит погашение исторического долга с бэкоффом;
     - при достижении `R_BUYOUT` завершает аренду со статусом `BUYOUT`.

3. **`external-stubs`**
   - Отдельный сервис, предоставляющий HTTP-заглушки всех внешних источников:
     - `/station-data`
     - `/tariff`
     - `/user-profile`
     - `/configs`
     - `/eject-powerbank`
     - `/hold-money-for-order`
     - `/clear-money-for-order`
   - Имитирует реальные внешние системы для отработки стратегий деградации и кэширования.

### Хранение данных

**Решение:** единая БД PostgreSQL (в docker-compose; в юнит-тестах — `sqlite+pysqlite`) с пятью ключевыми сущностями:

- `rentals` — состояние аренды;
- `idempotency_keys` — поддержка идемпотентности `/start`;
- `quotes` — одноразовые офферы с TTL;
- `payment_attempts` — аудит всех попыток списаний;
- `debts` — текущее состояние долга по арендам.

Обе службы (`rental-core` и `billing-worker`) используют одну и ту же схему (ORM-модели синхронизированы).

### Работа с внешними источниками и надёжность

**Решение по критичности источников:**

- `stations` — **критичный**:
  - при недоступности станций — запрос аварийно завершается (`5xx`), аренду начать нельзя.

- `configs` — **некритичный, но обязательный на старте**:
  - при старте сервиса конфиг должен быть успешно загружен; в противном случае сервис не поднимается;
  - далее используется закэшированное значение + периодическое обновление.

- `tariffs` — **некритичный, с кэшем**:
  - используется LRU-кэш с TTL (`TARIFF_TTL_SEC`);
  - устаревшие данные удаляются и пере-запрашиваются;
  - при временной недоступности тарифов возможны ошибки ответа, но процесс в целом не падает.

- `users` — **некритичный, с фоллбэком**:
  - при недоступности профиля — используется жадный фоллбэк (нет подписки, пользователь не trusted).

- `payments` — **некритичный**:
  - при недоступности платежей на старте аренды депозит превращается в долг;
  - при ошибках в биллинге растёт долг, который потом ретраится.

### Биллинг

**Решение:** вынести денежную логику в отдельный сервис-воркер:

- регулярные списания выполняет только `billing-worker`;
- API (`rental-core`) остаётся быстрым и простым (создание/закрытие аренды и чтение статуса);
- денежное состояние (`total_amount`, `debt`, `BUYOUT`) рассчитывается централизованно.

---

## Схема системы и потоки запросов

### Основные последовательности запросов

**1) `POST /rentals/quote`**

* `rental-core`:

  * вызывает через клиентов:

    * `/station-data` → `stations`;
    * `/tariff` → `tariffs`;
    * `/user-profile` → `users`;
  * считает цену, free_period, депозит;
  * записывает строку в `quotes` с `expires_at = now() + 60s`;
  * возвращает `quote_id` и параметры.

**2) `POST /rentals/start`**

* проверка идемпотентности по `Idempotency-Key` в `idempotency_keys`:

  * если ключ есть — вернуть сохранённый ответ;
* проверка квоты:

  * загрузка из `quotes` по `quote_id`;
  * проверка `expires_at > now()`; иначе 4xx;
  * поглощение квоты (delete);
* `clients.eject_powerbank(station_id)` → `/eject-powerbank`;
* создание записи `Rental` со статусом `"ACTIVE"`;
* попытка `hold_money_for_order`:

  * при успехе — депозит удержан;
  * при ошибке — депозит добавляется в `debts` как долг;
* сохранение ответа в `idempotency_keys`.

**Более подробно:**
Поглощение квоты = сделать оффер одноразовым: после успешного старта аренды этот quote больше нельзя использовать.

Логика POST /rentals/start по шагам:

Проверяем идемпотентность по Idempotency-Key.

Грузим quote из quotes, проверяем expires_at > now().

Выдаем powerbank через eject_powerbank.

Создаём запись в rentals (статус ACTIVE).

Пытаемся списать/заморозить депозит:

при успехе — OK;

при ошибке — вешаем долг в debts на сумму депозита (_attach_deposit_debt), аренда всё равно продолжается.

Квота считается использованной независимо от исхода депозита (по ТЗ: «если средств нет – навесить долг»).

TLDR: Если депозит не списался, аренда всё равно стартует, депозит уходит в долг, повторно использовать тот же quote нельзя.

**Дополнительные пояснения**

Idempotency-Key генерируется клиентом: случайный UUID на каждую попытку start.
Бэкенд его требует: если заголовка нет — 400 missing Idempotency-Key.
В БД есть таблица idempotency_keys с полями: key (PK), scope, user_id, response_json, created_at.
При повторном запросе с тем же ключом возвращаем сохранённый response_json без повторного старта аренды.

Почему не quote_id

quote_id — идентификатор оффера,
Idempotency-Key — идентификатор HTTP-запроса (попытки старта).
Один quote_id может участвовать в нескольких ретраях (разные клиенты, сети и т.д.).
Таблица idempotency_keys сделана универсальной (через scope), не только под start, поэтому не завязываем ключ на бизнес-сущность quote.

**3) Периодическая обработка биллингом**

* `billing-worker` по таймеру:

  * выбирает активные `rentals`;
  * считает `due` по тарифу и времени;
  * суммирует уже оплаченные `PaymentAttempt`;
  * читает долг `Debts`;
  * до-снимает деньги или гасит исторический долг;
  * при достижении `R_BUYOUT` ставит статус `BUYOUT` и `finished_at`.

**4) `GET /rentals/{order_id}/status`**

* `rental-core` возвращает:

  * `status` (`ACTIVE`, `FINISHED`, `BUYOUT`, …);
  * `powerbank_id`;
  * `total_amount`;
  * `debt`.

**5) `POST /rentals/{order_id}/stop`**

* если аренда уже `FINISHED` — возврат текущего состояния;
* иначе:

  * выставляется `FINISHED`, `finished_at = now()`;
  * выполняется `clear_money_for_order` (финальное списание/разбор депозита);
  * возможные ошибки платежей ведут к долгам, но не отменяют завершение аренды.

---

## Основные сущности БД

1. **`rentals`** — аренда:

   * `id` — PK, UUID;
   * `user_id`;
   * `powerbank_id`;
   * `price_per_hour`;
   * `free_period_min`;
   * `deposit`;
   * `status` — `"ACTIVE"`, `"FINISHED"`, `"BUYOUT"`, …;
   * `total_amount` — уже списанная сумма;
   * `started_at`, `finished_at`.

2. **`idempotency_keys`** — идемпотентность:

   * `key` — PK (`Idempotency-Key`);
   * `scope` (например, `"start"`);
   * `user_id`;
   * `response_json` — сериализованный ответ на повторную выдачу.

3. **`quotes`** — офферы:

   * `id` (`quote_id`) — PK;
   * `user_id`;
   * `station_id`;
   * `price_per_hour`, `free_period_min`, `deposit`;
   * `expires_at` — TTL оффера;
   * `created_at`.

4. **`payment_attempts`** — попытки списаний:

   * `id` — PK;
   * `rental_id`;
   * `amount`;
   * `success` (bool);
   * `error` (nullable text);
   * `created_at`.

5. **`debts`** — долги:

   * `rental_id` — PK;
   * `amount_total` — текущий долг;
   * `updated_at`;
   * `attempts` — число неуспешных попыток списания;
   * `last_attempt_at`.

---

## Расчёт нагрузки

### Нагрузка по HTTP-handler’ам

Задано:

* X = 10 RPS на создание аренды (`/rentals/start`);
* Y = 10 пользователей, каждый раз в минуту вызывает `/status`.

Пусть система в steady-state.

Приближения:

* **`POST /rentals/quote`**
  Предположим, к каждому `start` предшествует `quote`:
  `RPS_quote ≈ X = 10`.

* **`POST /rentals/start`**
  `RPS_start ≈ X = 10`.

* **`POST /rentals/{order_id}/stop`**
  В среднем число стопов примерно равно числу стартов, но равномерно размазано во времени.
  Для оценки берем `RPS_stop ~ 10` (можно заложиться меньше).

* **`GET /rentals/{order_id}/status`**
  `RPS_status = Y / 60 = 10 / 60 ≈ 0.17 RPS`.

Итого по HTTP (оценочно):

* write-операции (quote / start / stop): **20–30 RPS**;
* read-операции (`status`): ~ **0.2 RPS**.

### Нагрузка на БД

На один `start`:

* чтение квоты (`quotes`) — 1 read;
* удаление квоты — 1 write;
* создание `rental` — 1 write;
* создание `idempotency_key` — 1 write;
* при падении `hold_money_for_order` — доп. 1 write в `debts`.

Итого на X = 10 RPS по `/start` имеем:

* чтения: ~10 RPS;
* записи: ~30–40 RPS (с учётом `quote` и стопов).

На один `tick_once` в `billing-worker`:

* чтение списка активных `rentals` — 1 read;
* на каждую аренду:

  * read из `payment_attempts`;
  * read из `debts`;
  * при изменениях: write в `payment_attempts`, `debts`, иногда update `rentals`.

Даже при десятках RPS на запись и сопоставимом количестве чтений, текущая нагрузка для PostgreSQL комфортна и масштабируется через реплики для чтения.

### Расчёт хранения

При Z = 1 kB:

* один заказ ≈ 1 kB в `rentals` + небольшой overhead в `payment_attempts` и `debts`.

При 10 RPS и работе системы 1 час:

* за час: `10 * 3600 = 36 000` заказов → ≈ 36 MB;
* за сутки: ~864 000 заказов → ≈ 864 MB, то есть около 1 GB.

Стратегии оптимизации:

* архивирование старых аренд;
* очистка `payment_attempts` и `debts` после полного погашения.

---

## Implications / Плюсы и возможные доработки

**Плюсы решения:**

* Чёткое разделение зон ответственности:

  * `rental-core` — HTTP-API и бизнес-состояние;
  * `billing-worker` — денежная логика и периодические операции;
  * `external-stubs` — внешний мир.
* Простая горизонтальная масштабируемость:

  * `rental-core` stateless, масштабируется по X и Y;
  * биллинг можно шардировать.
* NFR:

  * maintainability — модульная структура, отдельные клиенты, понятные модели;
  * reliability — деградация по некритичным источникам, строгие правила для критичного `stations`;
  * scalability — расчёт нагрузки и архитектура под горизонтальный скейлинг.

## Notes / Open questions

* При росте нагрузки шардирование аренд или очередь задач
* Подключена полноценная система метрик (Prometheus/Grafana)
* Схема взаимодействия микросервисов и БД через mermaid
* Circuit breaker




## Related artifacts / Связанные артефакты

Архитектурное решение опирается на следующие артефакты и влияет на них:

- **Диаграмма взаимодействия микросервисов (Mermaid).**  
  Показывает потоки запросов между `rental-core`, `billing-worker`, `external-stubs` и БД.

- **`docker-compose.yml`.**  
  Описывает запуск `rental-core`, `billing-worker`, `external-stubs` и PostgreSQL в локальном окружении.

- **Отчёт о выполненной работе**  

- **Детали реализации**  
